<meta charset="utf-8">
<div class="entry-content">
 <p>
  The supercomputing community is moving toward extreme scale, which changes how we analyze simulation results. While large-scale visualization typically tends to be less interactive, we have developed an image-based approach to extreme-scale data analysis, ParaView Cinema, that enables interactive exploration and metadata browsing.
 </p>
 <p>
  <span id="docs-internal-guid-fe5d40b4-5f75-b559-2b81-82937cd5aab2">
   <img height="267px;" src="https://lh5.googleusercontent.com/xkiLy7_br2mVBC6-8xNSGo0_dg8E56gA6SFk-cYLTtoqSQYuT65ichhyGko-HW1wYGtEN1J5_HMRjoLYzlxZ_LptLo8tLlMg7TesWPqJZjJdG93JOWqN3rcYGgzryl6I9Q" style="border:none;" width="437px;"/>
  </span>
 </p>
 <p>
  Cinema is an open-source, novel framework built on top of ParaView that couples processing exporters and a client user interface for output analysis using images or other types of reduced data. Cinema captures images based on several camera positions and filter configurations.
 </p>
 <p>
  With Cinema, data processing and visualization occur in-situ or in batch mode to produce a set of pre-computed images or reduced data. Those will then be used later on to interactively analyze the simulation results. Unlike traditional in situ approaches, Cinema focuses on gathering a larger set of images (including camera positions, operations, and parameters to operations) to produce explorable results. Thanks to the lightweight nature of the data generated using cinema, the analysis and exploration of those results can be done using standard Web technologies.
 </p>
 <p>
  Cinema’s interface for interactive exploration mimics standard mouse interaction for 3D data such as rotation, panning, and zooming.
 </p>
 <p align="center">
  <span id="docs-internal-guid-fe5d40b4-5f75-ea18-ae1c-08b34eec0459">
   <img height="206px;" src="https://lh6.googleusercontent.com/s89dmThbQspcieGV8HRFbsoQGll8aMY1p0OQm6KFuRNS-WJdDcEylRGZXxGMq_GOfAkP-W84F5Hz01dvNaX6KxmcvSsLpP6Dx5a2dTjBXre1bqQOofud2t_t--H2AksR-w" style="border:none;" width="199px;"/>
  </span>
 </p>
 <p align="center">
  <em>
   Pan and zoom
  </em>
 </p>
 <p align="center">
  <span id="docs-internal-guid-fe5d40b4-5f76-297d-b0e5-b2a967d54a02">
   <img height="129px;" src="https://lh6.googleusercontent.com/nUJT3qpYniq-0IQkJQc7NAnKD4viK6_kgppGQb0A36ziE4aAcnP_aEvFuyajwirj_w0hq-bBT_7ZLosTlxgOMRrwdkV9R_uCFW_QUmUCNPvUKF-hqWwzhPTtGV9diLcAvg" style="border:none;" width="124px;"/>
   <img height="129px;" src="https://lh6.googleusercontent.com/nUJT3qpYniq-0IQkJQc7NAnKD4viK6_kgppGQb0A36ziE4aAcnP_aEvFuyajwirj_w0hq-bBT_7ZLosTlxgOMRrwdkV9R_uCFW_QUmUCNPvUKF-hqWwzhPTtGV9diLcAvg" style="border:none;" width="124px;"/>
   <img height="129px;" src="https://lh6.googleusercontent.com/nUJT3qpYniq-0IQkJQc7NAnKD4viK6_kgppGQb0A36ziE4aAcnP_aEvFuyajwirj_w0hq-bBT_7ZLosTlxgOMRrwdkV9R_uCFW_QUmUCNPvUKF-hqWwzhPTtGV9diLcAvg" style="border:none;" width="124px;"/>
   <img height="129px;" src="https://lh6.googleusercontent.com/nUJT3qpYniq-0IQkJQc7NAnKD4viK6_kgppGQb0A36ziE4aAcnP_aEvFuyajwirj_w0hq-bBT_7ZLosTlxgOMRrwdkV9R_uCFW_QUmUCNPvUKF-hqWwzhPTtGV9diLcAvg" style="border:none;" width="124px;"/>
  </span>
 </p>
 <p align="center">
  <em>
   Rotation
  </em>
 </p>
 <p>
  The difference is that Cinema relies on pre-rendered images to emulate interactive navigation around an object. This means that, when using the navigation, it will seem as if you are interactively rendering images from a 3D model. In reality, Cinema will just browse through its existing set of pre-computed images like Google Street view.
 </p>
 <p>
  <span id="docs-internal-guid-fe5d40b4-5f76-e4be-eb88-42169b1553d9">
   <img height="158px;" src="https://lh6.googleusercontent.com/u4OCIgN7vq4o0hhGh08EtVTtdn_77F_25yj9t4KtgayWZJ-ieFJf1lEWp_3BD2hMxdOtksUd1Emgrijvb275ZGHBfTuQEVskxH0ZDkeyGmtZl8G8PNtxWzKkJl63_MZd5w" style="border:none;" width="319px;"/>
  </span>
  <span id="docs-internal-guid-fe5d40b4-5f77-074e-fa1a-80138259583b">
   <img height="153px;" src="https://lh5.googleusercontent.com/v-ifssWmV9Jgr2t9UXKhKtw1sod6t7rtNYF7SCKvxuLKWns9jhJzgPPmatTRqKCz5hPCYOTxVu9PyvR2GkjMVYZnQixyyKD5sTwftrXf2nc9ixKvYO1P3Vicyu4cxLSm4w" style="border:none;" width="152px;"/>
  </span>
 </p>
 <p>
  As for future developments, we are currently working on improving the graphical web client with a more refined and solid user experience.
 </p>
 <p>
 </p>
 <p>
  <a href="/blog/files/331_648489532.jpg" target="_blank">
   <img src="https://blog.kitware.com/blog/files/Small.331_648489532.jpg" width="100%"/>
  </a>
 </p>
 <p>
  This work with the Los Alamos National Laboratory led us to a paper at
  <a href="http://sc14.supercomputing.org">
   SuperComputing 2014
  </a>
  named “An Image-based Approach to Extreme Scale In Situ Visualization and Analysis,” which will be presented by James Ahrens at the conference in New Orleans on November 19th at 11:30AM in rooms 391-92.
 </p>
 <div>
  <p>
  </p>
 </div>
</div>

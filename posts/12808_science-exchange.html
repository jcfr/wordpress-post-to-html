<meta charset="utf-8">
<div class="entry-content">
 <p>
  A very interesting new player in scientific research:
 </p>
 <p style="text-align: center;">
  <span style="font-size: medium;">
   <a href="http://blog.scienceexchange.com/">
    “Science Exchange”
   </a>
  </span>
 </p>
 <p style="text-align: center;">
  <em>
   “Science Exchange is a community-driven marketplace for science experiments.
   <br/>
   We make it easy for research scientists to access experimental services
   <br/>
   by providing a way to search for an experiment type, view and compare
   <br/>
   providers, and choose a provider to work with. “
  </em>
 </p>
 <p style="text-align: center;">
  <em>
   <a href="http://blog.scienceexchange.com/">
    <img alt="science exchange logo" height="95" src="http://blog.scienceexchange.com/wp-content/themes/scienceexchange/images/logo.png" width="300"/>
   </a>
   <br/>
  </em>
 </p>
 <p>
  This is a novel contribution to addressing the lack of reproducibility that is rampant in scientific research today.
 </p>
 <p>
  In a recent blog,
  <a href="http://elizabethiorns.com/">
   Elizabeth Lorns
  </a>
  raises awareness about the need for verifying reproducibility. She writes:
 </p>
 <p style="padding-left: 30px;">
  <em>
   An increasing number of reports have found discrepancies in published
   <br/>
   preclinical studies across scientific disciplines. For instance:
  </em>
 </p>
 <ul>
  <li>
   <em>
    Amgen found that
    <a href="http://news.yahoo.com/cancer-science-many-discoveries-dont-hold-174216262.html" target="_blank">
     47 of 53 “landmark” oncology publications
    </a>
    could not be reproduced.
   </em>
  </li>
  <li>
   <em>
    Bayer found that
    <a href="http://blogs.nature.com/news/2011/09/reliability_of_new_drug_target.html" target="_blank">
     43 of 67 oncology &amp; cardiovascular projects
    </a>
    were based on contradictory
    <br/>
    results from academic publications.
   </em>
  </li>
  <li>
   <em>
    Dr. John Ioannidis and his colleagues found that of
    <a href="http://online.wsj.com/article/SB118972683557627104.html">
     432 publications purporting sex differences
    </a>
    <br/>
    in hypertension, multiple sclerosis, or lung cancer, only one dataset was reproducible.
   </em>
  </li>
 </ul>
 <p>
  and points out to an essential component of the solution:
 </p>
 <ul>
  <li>
   <em>
    Funding agencies should
    <strong>
     allocate
    </strong>
    some proportion of a grant
    <br/>
    to allow research groups to include independent replication in their project work flow.
   </em>
  </li>
  <li>
   <em>
    Journal editors should
    <strong>
     encourage independent replication
    </strong>
    of key results prior to publication.
   </em>
  </li>
 </ul>
 <p>
 </p>
 <p>
  Science Exchange is essentially an:
 </p>
 <p style="padding-left: 30px;">
  <em>
   “…online marketplace for outsourcing experiments, we make it easy to verify experiments and key findings at independent research sites. Our platform is well positioned to help funding agencies and journal editors ensure greater reproducibility in the research they fund and publish by making it easy for researchers to implement reproducibility into their project work flow.”
  </em>
 </p>
 <p>
  The business model is quite clever:
 </p>
 <p style="text-align: center;">
  Funding agencies and journals could contract their services to replicate a particular experiment.
 </p>
 <p>
  In this way, reproducibility can systematically be brought back into the mainstream of scientific research, where it belongs.
 </p>
 <p>
  They can also serve as an accreditation body, capable of giving a “…
  <em>
   reproducibility ‘stamp of approval’.
  </em>
  “
 </p>
 <p>
  One could picture soon, that
 </p>
 <ol>
  <li>
   Papers could include a label indicating that their experiments
   <br/>
   were replicated by independent observers at Science Exchange.
  </li>
  <li>
   Journals could start requiring that experiments from a paper
   <br/>
   be replicated at Science Exchange, before the paper is approved for publication.
  </li>
  <li>
   Funding agencies could give brownie points to grant applications where researchers
   <br/>
   provide Science Exchange certificates of reproducibility from previous work.
  </li>
 </ol>
 <p>
 </p>
 <p>
  Overall, this is a great step in the right direction. With this resource, before we ask about the novelty of research work, we can take the rational step of asking first:
 </p>
 <ul>
  <li>
   “Is it true?”
  </li>
  <li>
   “Does it work?”
  </li>
 </ul>
 <p>
  These are just a couple of basic questions that unfortunately most journals and conferences today do not care to ask.
 </p>
 <p>
  Thanks to
  <a href="https://www.scienceexchange.com/">
   Science Exchange
  </a>
  , people who are serious about science, and who therefore truly care about whether experiments are reproducible or not, now have a marketplace to connect service providers with customers and in a pragmatic manner solve the question of reproducibility verification.
 </p>
 <p>
  With more than 1,000 registered providers, and more than 800 types of experiments available, Science Exchange is well beyond the stage of proving that the idea is feasible. Example of available services include: transgenic mice experiments, and microgravity experiments that run in the International Space Station.
 </p>
 <p>
 </p>
 <p style="text-align: center;">
  Kudoz to Science Exchange for restoring the principles of the Scientific Method!
 </p>
 <p style="text-align: center;">
 </p>
 <p style="text-align: center;">
  <span style="font-size: medium;">
   <strong>
    Nullius in Verba !
   </strong>
  </span>
 </p>
</div>

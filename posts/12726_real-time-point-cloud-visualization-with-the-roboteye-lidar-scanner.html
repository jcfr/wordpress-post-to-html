<meta charset="utf-8">
<div class="entry-content">
 <p>
  <a href="/blog/files/174_1542296935.png" rel="noopener" target="_blank">
   <img alt="" height="32" src="https://blog.kitware.com/blog/files/Small.174_1542296935.png" width="280"/>
  </a>
  <img alt="" height="44" src="https://blog.kitware.com/blog/files/Small.174_220997925.png" width="129"/>
 </p>
 <p>
  The PCL-Ocular Robotics code sprint has concluded. For this event I participated as the code sprint developer and worked with engineers at Ocular Robotcs to develop a lidar grabber interface to the
  <a href="http://www.ocularrobotics.com/products.html">
   RE0x laser scanners
  </a>
  for the Point Cloud Library.  This was my second time participating in a PCL code sprint; last year I worked on a code sprint to develop
  <a href="https://blog.kitware.com/point-cloud-streaming-to-mobile-devices-with-real-time-visualization/">
   point cloud streaming mobile apps
  </a>
  .
 </p>
 <p>
  The goals of the PCL-Ocular Robotics code sprint were to develop a point cloud grabber using the pcl::Grabber interface and to develop visualization code to support real-time visualization of lidar point cloud data acquired by the RobotEye laser scanner.
 </p>
 <p style="text-align: center;">
  <a href="/blog/files/174_116041455.png" rel="noopener" target="_blank">
   <img alt="" height="228" src="https://blog.kitware.com/blog/files/Small.174_116041455.png" width="152"/>
  </a>
  <a href="https://www.kitware.com/blog/files/174_565138649.png" rel="noopener" target="_blank">
   <img alt="" height="235" src="https://www.kitware.com/blog/files/Small.174_565138649.png" width="132"/>
  </a>
  <a href="/blog/files/174_1245646565.png" rel="noopener" target="_blank">
   <img alt="" height="221" src="https://blog.kitware.com/blog/files/Small.174_1245646565.png" width="155"/>
  </a>
 </p>
 <p>
  I developed a cross-platform Qt application called RobotEye Viewer, which uses the RobotEye C++ API to send control messages to the RobotEye scanner and displays point cloud streams acquired using the newly-developed pcl::RobotEyeGrabber interface.  The visualization is performed using the PCLVisualizer. The PCLVisualizer is a C++ class provided by the pcl visualization library which is built on VTK. The PCLVisualizer wraps a vtkRenderWindow which is embedded into the RobotEye Viewer application using the QVTKWidget.
 </p>
 <p>
  The following video demonstrates the RobotEye Viewer application in action using a RE05 laser scanner:
 </p>
 <p>
  Earlier in the development process, Ocular Robotics sent me some lidar scans in a binary format to get started. The data was stored in binary files with azimuth, elevation, range, and intensity fields. I wrote some code to load the binary data and convert it to the pcl::PointCloud data structure. From there, I saved the data in the pcd file format and opened it with
  <a class="reference external" href="http://paraview.org">
   ParaView
  </a>
  using the
  <a class="reference external" href="http://www.paraview.org/Wiki/ParaView/PCL_Plugin">
   PCL Plugin for ParaView
  </a>
  . I used ParaView’s animation controls to create a video of the lidar scan.
 </p>
 <p>
  Here is a video of a RobotEye scan (not displayed in real-time) of the Great Hall in Sydney, Australia:
 </p>
 <p>
 </p>
 <p>
  Here’s a screenshot of the RobotEye Viewer application running on MacOSX:
 </p>
 <p>
  <a href="/blog/files/174_1636275068.png" rel="noopener" target="_blank">
   <img alt="" height="305" src="https://blog.kitware.com/blog/files/Small.174_1636275068.png" style="display: block; margin-left: auto; margin-right: auto;" width="520"/>
  </a>
  <br/>
  The RobotEye grabber was developed using the pcl::Grabber interface. PCL incudes grabber interfaces for other sensor types, too.  For example, RGB-D cameras like the Microsoft Kinect can be used through the pcl::OpenNIGrabber.
 </p>
 <p>
  The
  <a href="http://www.paraview.org/Wiki/ParaView/PCL_Plugin">
   PCL Plugin for ParaView
  </a>
  uses a VTK filter to wrap the grabber interface so that you can use ParaView to acquire point clouds from Kinect cameras. The following video shows how ParaView can be used to build a point cloud segmentation pipeline to process point cloud streams captured from the Kinect camera:
 </p>
 <p>
 </p>
 <p>
  Additional resources:
 </p>
 <ul>
  <li>
   <a href="http://pointclouds.org/blog/orcs/">
    http://pointclouds.org/blog/orcs/
   </a>
  </li>
  <li>
   <a href="http://pointclouds.org/documentation/">
    http://pointclouds.org/documentation/
   </a>
  </li>
  <li>
   <a href="http://www.paraview.org/Wiki/ParaView/PCL_Plugin">
    http://www.paraview.org/Wiki/ParaView/PCL_Plugin
   </a>
  </li>
 </ul>
</div>
